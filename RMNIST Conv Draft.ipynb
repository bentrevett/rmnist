{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cognitivemedium.com/rmnist\n",
    "\n",
    "CNN:\n",
    "- RMNIST/1: 56.91%\n",
    "- RMNIST/5: 76.65%\n",
    "- RMNIST/10: 86.53%\n",
    "- MNIST: 99.11%\n",
    "\n",
    "With data transformations:\n",
    "- RMNIST/1: 55.25%\n",
    "- RMNIST/5: 84.38%\n",
    "- RMNIST/10: 92.07%\n",
    "- MNIST: 99.34%\n",
    "\n",
    "With transfer learning:\n",
    "- RMNIST/1: 51.01%\n",
    "- RMNIST/5: 72.81%\n",
    "- RMNIST/10: 82.95%\n",
    "\n",
    "With transfer learning and data transformations:\n",
    "- RMNIST/1: 52.84%\n",
    "- RMNIST/5: 75.27%\n",
    "- RMNIST/10: 84.66%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX, teX, trY, teY = data_utils.load_mnist(one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(trX.shape)\n",
    "print(trX.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "float64\n",
      "(50, 784)\n",
      "float64\n",
      "(10000,)\n",
      "uint8\n",
      "(50,)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "N = 5\n",
    "\n",
    "counts = defaultdict(int) #need to keep track of how many of each digit\n",
    "indices = list(range(50000))\n",
    "random.shuffle(indices)\n",
    "\n",
    "valX, valY = trX[50000:], trY[50000:]\n",
    "rtrX, rtrY = np.zeros((N*10,784)), np.zeros((N*10), dtype=np.uint8)\n",
    "     \n",
    "i = 0\n",
    "for index in indices:\n",
    "    if counts[trY[index]] < N:\n",
    "        rtrX[i], rtrY[i] = trX[index], trY[index]\n",
    "        counts[trY[index]] += 1\n",
    "        i += 1\n",
    "        \n",
    "print(valX.shape)\n",
    "print(valX.dtype)\n",
    "print(rtrX.shape)\n",
    "print(rtrX.dtype)\n",
    "print(valY.shape)\n",
    "print(valY.dtype)\n",
    "print(rtrY.shape)\n",
    "print(rtrY.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0ERfiAowg8E9T9FgXQbXNjfGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1bf6d67128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#view data\n",
    "\n",
    "plt.imshow(rtrX[(N*10)-1].reshape(28,28), cmap=plt.get_cmap('gray')); #need cmap thing or else is weird colour\n",
    "print(rtrY[(N*10)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(rtrY, return_counts=True)) #making sure there's N of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_shift(X, max_shift=3, n_pixels=None):\n",
    "\n",
    "    X = np.copy(X)\n",
    "    \n",
    "    if n_pixels.any() == None:\n",
    "        n_pixels = np.random.randint(0,max_shift+1,4) #args are low, max, n, with max being exclusive, i.e. 0, 5, 4 produces 4 numbers between 0 and 4\n",
    "    \n",
    "    #shifting image up by n_pixels\n",
    "    if n_pixels[0]:\n",
    "        X[:28*28-n_pixels[0]*28] = X[n_pixels[0]*28:]\n",
    "        X[28*28-n_pixels[0]*28:] = np.zeros(n_pixels[0]*28)\n",
    "        \n",
    "    #shifting image right by n_pixels\n",
    "    if n_pixels[1]:\n",
    "        X = X.reshape(28,28)\n",
    "        X[:,n_pixels[1]:] = X[:,:28-n_pixels[1]]\n",
    "        X[:,:n_pixels[1]] = np.zeros((28,n_pixels[1]))\n",
    "        X = X.reshape(28*28)\n",
    "        \n",
    "    #shifting image down by n_pixels\n",
    "    if n_pixels[2]:\n",
    "        X[n_pixels[2]*28:] = X[:28*28-n_pixels[2]*28]\n",
    "        X[:n_pixels[2]*28] = np.zeros(n_pixels[2]*28)\n",
    "        \n",
    "    #shifting image left by n_pixels\n",
    "    if n_pixels[3]:\n",
    "        X = X.reshape(28,28)\n",
    "        X[:,:28-n_pixels[3]] = X[:,n_pixels[3]:]\n",
    "        X[:,28-n_pixels[3]:] = np.zeros((28,n_pixels[3]))\n",
    "        X = X.reshape(28*28)\n",
    "\n",
    "    assert X.shape[0] == 28*28\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "\n",
    "max_shift=5 #5 got me 86%\n",
    "#rotations = np.linspace(-45,+45,2)\n",
    "rotations = [1]\n",
    "shifts = np.zeros(((max_shift+1)**4,4), dtype=np.uint8) #values 0 to 5 (exclusive), array length of 4\n",
    "count = 0\n",
    "\n",
    "for i in range(max_shift+1):\n",
    "    for j in range(max_shift+1):\n",
    "        for k in range(max_shift+1):\n",
    "            for l in range(max_shift+1):\n",
    "                shifts[count][0] = i\n",
    "                shifts[count][1] = j\n",
    "                shifts[count][2] = k\n",
    "                shifts[count][3] = l\n",
    "                count+=1\n",
    "                \n",
    "assert count == (max_shift+1)**4\n",
    "\n",
    "trX = np.zeros((rtrX.shape[0]*count*len(rotations),28*28))\n",
    "trY = np.zeros((rtrX.shape[0]*count*len(rotations),))\n",
    "        \n",
    "count = 0\n",
    "index = 0\n",
    "    \n",
    "for X, y in zip(rtrX, rtrY):\n",
    "    for s in shifts:\n",
    "        shiftedX = random_shift(X, max_shift, n_pixels=s)\n",
    "        #for rot in rotations:\n",
    "            #rotatedX = misc.imrotate(shiftedX.reshape(28,28), rot).reshape(28*28)\n",
    "        trX[count], trY[count] = shiftedX, y  \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen: cannot load any more object with static TLS",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7ed6526d968d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch-practice/lib/python3.6/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dl_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0m_dl_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_NOW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen: cannot load any more object with static TLS"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RMNIST(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        assert len(X) == len(y)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        img = img.reshape(28, 28)\n",
    "        img = img+np.random.normal(0,0.03,size=(28,28)) #add some random noise\n",
    "        img = torch.FloatTensor(img)\n",
    "        label = torch.from_numpy(np.array([label])).long()\n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "train_dataset = RMNIST(trX, trY)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = RMNIST(valX, valY)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(F.dropout2d(self.conv2(x), 0.5), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #prob it will be zero\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "lr = 0.1\n",
    "momentum = 0\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, epoch):\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr*((0.8)**(epoch/10+1)), momentum=momentum)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        \n",
    "        X, y = Variable(X), Variable(y)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = F.nll_loss(output, y.squeeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    for i, (X, y) in enumerate(val_loader):\n",
    "        \n",
    "        X, y = Variable(X), y.squeeze(1)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        batch_correct = (predicted == y).sum()\n",
    "        correct += batch_correct\n",
    "        \n",
    "    return correct/len(val_loader)*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    train(model, epoch)\n",
    "    acc = predict(model)\n",
    "    print(f'Epoch: {epoch}, Acc: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "X = rtrX[(N*10)-1]\n",
    "\n",
    "plt.imshow(X.reshape(28,28), cmap=plt.get_cmap('gray')); #need cmap thing or else is weird colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "\n",
    "plt.imshow(misc.imrotate(X.reshape(28,28), -45), cmap=plt.get_cmap('gray')); #need cmap thing or else is weird colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(misc.imrotate(X.reshape(28,28), -35), cmap=plt.get_cmap('gray')); #need cmap thing or else is weird colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(-45,+45,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
